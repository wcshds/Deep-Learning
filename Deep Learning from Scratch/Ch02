{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ch02","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMaQB4RRtDc7CbI7jw26Unc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Aza7eeN91ZTt"},"source":["# 感知機\n","本章將介紹**感知機**（perceptron）這一算法。感知機是由美國學者Frank Rosenblatt在1957年提出來的。爲何我們現在還要學習這一很久以前就有的算法呢？因爲感知機也是作爲神經網絡（深度學習）的起源的算法。因此，學習感知機的構造也就是學習通向神經網絡和深度學習的一種重要思想。\n","\n","本章我們將簡單介紹一下感知機，並用感知機解決一些簡單的問題。希望大家通過這個過程能熟悉感知機。"]},{"cell_type":"markdown","metadata":{"id":"O_bSeD8v6UGE"},"source":["## 2.1 感知機是什麽\n","\n","感知機接收多個輸入信號，輸出一個信號。這裏所說的「信號」可以想象成電流或河流那樣具備「流動性」的東西。像電流流過導綫，向前方輸送電子一樣，感知機的信號也會形成流，向前方輸送信息。但是，和實際的電流不同的是，感知機的信號只有「流/不流」（$1$/$0$）兩種取值。在本教程中，$0$對應「不傳遞信號」，$1$對應「傳遞信號」。\n","\n","圖2-1是一個接收兩個輸入信號的感知機的例子。$x_{1}$、$x_{2}$是輸入信號，$y$是輸出信號，$w_{1}$、$w_{2}$是權重（$w$是weight的首字母）。圖中的&xcirc;稱爲「神經元」或者「節點」。輸入信號被送往神經元時，會被分別乘以固定的權重（$w_{1}x_{1}$、$w_{2}x_{2}$）。神經元會計算傳送過來的信號的總和，衹有當這個總和超過了某個界限值時，才會輸出$1$。這也稱爲「神經元被激活」。這裡將這個界限值稱爲**閾值**，用符號$\\theta$表示。\n","\n","<div align=\"center\">\n","<img alt=\"有兩個輸入的感知機\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-1.png\" width=\"50%\">\n","<div style=\"display: inline-block;\"><strong>圖2-1 有兩個輸入的感知機</strong></div>\n","</div>\n","\n","感知機的運行原理衹有這些！把上述內容用數學式來表示，就是式（2.1）\n","\n","$$\n","y = \n","\\begin{cases}\n","0 & (w_{1}x_{1} + w_{2}x_{2}) \\leq \\theta \\\\\n","1 & (w_{1}x_{1} + w_{2}x_{2}) > \\theta\n","\\end{cases} \\tag{2.1}\n","$$\n","\n","感知機的多個輸入信號都有各自固有的權重，這些權重發揮着控制各個信號的重要性的作用。也就是說，權重越大，對應該權重的信號的重要性就越高。\n","\n","權重相當於電流裡所說的電阻。電阻是決定電流流動難度的參數，電阻越低，通過的電流就越大。而感知機的權重則是值越大，通過的信號就越大。不管是電阻還是權重，在控制信號流動難度（或者流動容易度）這一點上的作用都是一樣的。"]},{"cell_type":"markdown","metadata":{"id":"FNUrOiby_lg8"},"source":["## 2.2 簡單邏輯電路\n","\n","### 2.2.1 與門\n","\n","現在讓我們考慮用感知機來解決簡單的問題。這裡首先以邏輯電路爲題材來思考一下與門（AND gate）。與門是有兩個輸入和一個輸出的門電路。圖2-2這種輸入信號和輸出信號的對應表稱爲「眞值表」。如圖2-2所示，與門僅在兩個輸入均爲$1$時輸出$1$，其他時候則輸出$0$。\n","\n","<div align=\"center\">\n","<img alt=\"與門的眞值表\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-2.png\" width=\"50%\">\n","<div style=\"display: inline-block;\"><strong>圖2-2 與門的眞值表</strong></div>\n","</div>\n","\n","下面考慮用感知機來表示這個與門。需要做的就是確定能滿足圖2-2的眞值表的$w_{1}$、$w_{2}$、$\\theta$的值。那麼，設定什麽樣的值才能製作出滿足圖2-2的條件的感知機呢？\n","\n","實際上，滿足圖2-2的條件的參數的選擇方法有無數多個。比如，當$(w_{1},w_{2},\\theta)=(0.5,0.5,0.7)$時，可以滿足圖2-2的條件。此外，當$(w_{1},w_{2},\\theta)$爲$(0.5,0.5,0.8$)或者$(1.0,1.0,1.0)$時，同樣也滿足與門的條件。設定這樣的參數後，僅當$x_{1}$和$x_{2}$同時爲$1$時，信號的加權總和才會超過給定的閾值$\\theta$。\n","\n","### 2.2.2 與非門和或門\n","\n","接着，我們再來考慮一下與非門（NAND gate）。NAND是Not AND的意思，與非門就是顛倒了與門的輸出。用眞值表表示的話，如圖2-3所示，僅當$x_{1}$和$x_{2}$同時爲$1$時輸出$0$，其他時候則輸出$1$。那麽與非門的參數又可以是什麽樣的組合呢？\n","\n","<div align=\"center\">\n","<img alt=\"與非門的眞值表\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-3.png\" width=\"50%\">\n","<div style=\"display: inline-block;\"><strong>圖2-3 與非門的眞值表</strong></div>\n","</div>\n","\n","要表示與非門，可以用$(w_{1},w_{2},\\theta)=(−0.5,−0.5,−0.7)$這樣的組合（其他的組合也是無限存在的）。實際上，衹要把實現與門的參數值的符號取反，就可以實現與非門。\n","\n","接下來看一下圖2-4所示的或門。或門是「衹要有一個輸入信號是$1$，輸出就爲$1$」的邏輯電路。那麽我們來思考一下，應該爲這個或門設定什麽樣的參數呢？\n","\n","<div align=\"center\">\n","<img alt=\"或門的眞值表\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-4.png\" width=\"50%\">\n","<div style=\"display: inline-block;\"><strong>圖2-4 或門的眞值表</strong></div>\n","</div>\n","\n","<br/>\n","\n","*注意：*\n","\n","*這裡決定感知機參數的並不是計算機，而是我們人。我們看着眞值表這種「訓練數據」，人工考慮（想到）了參數的值。而機器學習的課題就是將這個決定參數值的工作交由計算機自動進行。**學習**是確定合適的參數的過程，而人要做的是思考感知機的構造（模型），並把訓練數據交給計算機。*\n","\n","<br/>\n","\n","如上所示，我們已經知道使用感知機可以表示與門、與非門、或門的邏輯電路。這裡重要的一點是：與門、與非門、或門的感知機構造是一樣的。實際上，3個門電路衹有參數的值（權重和閾值）不同。也就是說，相同構造的感知機，只需通過適當地調整參數的值，就可以像「變色龍演員」表演不同的角色一樣，變身爲與門、與非門、或門。"]},{"cell_type":"markdown","metadata":{"id":"dBNWTbw2CRwE"},"source":["## 2.3 感知機的實現"]},{"cell_type":"markdown","metadata":{"id":"3kNLuFtEEx6E"},"source":["### 2.3.1簡單的實現\n","\n","現在，我們用Python來實現剛才的邏輯電路。這裡，先定義一個接收參數x1和x2的AND函數。"]},{"cell_type":"code","metadata":{"id":"zsL-pQpv1RAk"},"source":["def AND(x1, x2):\n","  w1, w2, theta = 0.5, 0.5, 0.7\n","  temp = w1 * x1 + w2 * x2\n","  if temp <= theta:\n","    return 0\n","  elif temp > theta:\n","    return 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I7nBn_ZA30mT"},"source":["在函數內初始化參數w1，w2，theta，當輸入的加權總和超過閾值時返回1，否則返回0。我們來確認一下輸出的結果。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYAm2xoP17h5","executionInfo":{"status":"ok","timestamp":1634397305720,"user_tz":-480,"elapsed":16,"user":{"displayName":"吳琛","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGGN8VBMjqC5bhUWpteK796KQCvMPqhZq6A2ZX0A=s64","userId":"14227993174234273213"}},"outputId":"a245f0bb-af83-4074-e3f1-ccd0f07b1e09"},"source":["print(AND(0, 0))\n","print(AND(1, 0))\n","print(AND(0, 1))\n","print(AND(1, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","0\n","0\n","1\n"]}]},{"cell_type":"markdown","metadata":{"id":"_K4K6KT54Mgb"},"source":["這樣，我們就實現了與門。按照同樣的步驟，也可以實現與非門和或門。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWUWC01z4s47","executionInfo":{"status":"ok","timestamp":1634397305720,"user_tz":-480,"elapsed":14,"user":{"displayName":"吳琛","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGGN8VBMjqC5bhUWpteK796KQCvMPqhZq6A2ZX0A=s64","userId":"14227993174234273213"}},"outputId":"fd9058a4-8205-421f-e199-0970fe72eab5"},"source":["def NAND(x1, x2):\n","  w1, w2, theta = -0.5, -0.5, -0.7\n","  temp = w1 * x1 + w2 * x2\n","  if temp <= theta:\n","    return 0\n","  elif temp > theta:\n","    return 1\n","\n","print(NAND(0, 0))\n","print(NAND(1, 0))\n","print(NAND(0, 1))\n","print(NAND(1, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1\n","1\n","0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3OVeRx_44It","executionInfo":{"status":"ok","timestamp":1634397305721,"user_tz":-480,"elapsed":13,"user":{"displayName":"吳琛","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGGN8VBMjqC5bhUWpteK796KQCvMPqhZq6A2ZX0A=s64","userId":"14227993174234273213"}},"outputId":"6d61b8ab-de37-4cb2-b8dd-51cb03179a0f"},"source":["def OR(x1, x2):\n","  w1, w2, theta = 0.5, 0.5, 0.3\n","  temp = w1 * x1 + w2 * x2\n","  if temp <= theta:\n","    return 0\n","  elif temp > theta:\n","    return 1\n","\n","print(OR(0, 0))\n","print(OR(1, 0))\n","print(OR(0, 1))\n","print(OR(1, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","1\n","1\n"]}]},{"cell_type":"markdown","metadata":{"id":"t9xVkf8B5Z2s"},"source":["### 2.3.2 導入權重和偏置\n","\n","剛才的實現比較直接、容易理解，但是考慮到以後的事情，我們將其修改爲另外一種實現形式。在此之前，首先把式(2.1)的$\\theta$換成$-b$，於是就可以用式(2.2)來表示感知機的行爲。\n","\n","$$\n","y = \\begin{cases}\n","0 & (b + w_{1}x_{1} + w_{2}x_{2}) \\leqslant 0 \\\\\n","1 & (b + w_{1}x_{1} + w_{2}x_{2}) > 0\n","\\end{cases} \\tag{2.2}\n","$$\n","\n","式(2.1)和式(2.2)雖然有一個符號不同，但表達的內容是完全相同的。此處，$b$稱爲** **粗體文字**偏置**，$w_{1}$和$w_{2}$稱爲**權重**。如式(2.2)所示，感知機會計算輸入信號和權重的乘積，然後加上偏置，如果這個值大於0則輸出1，否則輸出0。下面，我們使用NumPy，按式(2.2)的方式實現感知機。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKr4s0ORAIap","executionInfo":{"status":"ok","timestamp":1634397305721,"user_tz":-480,"elapsed":11,"user":{"displayName":"吳琛","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGGN8VBMjqC5bhUWpteK796KQCvMPqhZq6A2ZX0A=s64","userId":"14227993174234273213"}},"outputId":"af44d6cb-bcd3-4543-8033-1447e398d066"},"source":["import numpy as np\n","x = np.array([0, 1])  # 輸入\n","w = np.array([0.5, 0.5])  # 權重\n","b = -0.7\n","print(w * x)\n","print(np.sum(w * x))\n","print(np.sum(w * x) + b)  # 浮點數運算有時會因爲精度産生誤差"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.  0.5]\n","0.5\n","-0.19999999999999996\n"]}]},{"cell_type":"markdown","metadata":{"id":"KZx_xcXUClhZ"},"source":["如上例所示，在NumPy數組的乘法運算中，當兩個數組的元素個數相同時，各個元素分別相乘，因此w*x的結果就是它們的各個元素分別相乘（\\[0, 1\\] &#42; \\[0.5, 0.5\\] => \\[0, 0.5\\]）。之後，np.sum(w&#42;x)再計算相乘之後的各個元素的總和。最後再把偏置加到這個加權總和上，就完成了式(2.2)的計算。"]},{"cell_type":"markdown","metadata":{"id":"sSThmh-mCGG4"},"source":["### 2.3.3 使用權重和偏置的實現\n","使用權重和偏置，可以像下面這樣實現與門。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZcRAvjsrE19f","executionInfo":{"status":"ok","timestamp":1634397305721,"user_tz":-480,"elapsed":10,"user":{"displayName":"吳琛","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGGN8VBMjqC5bhUWpteK796KQCvMPqhZq6A2ZX0A=s64","userId":"14227993174234273213"}},"outputId":"7e1a67bb-03b7-4bc8-b383-eedc33cb6cfd"},"source":["def AND(x1, x2):\n","  x = np.array([x1, x2])\n","  w = np.array([0.5, 0.5])\n","  b = -0.7\n","  temp = np.sum(w * x) + b\n","  if temp <= 0:\n","    return 0\n","  else:\n","    return 1\n","\n","print(AND(0, 0))\n","print(AND(1, 0))\n","print(AND(0, 1))\n","print(AND(1, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","0\n","0\n","1\n"]}]},{"cell_type":"markdown","metadata":{"id":"oKU8xtOmF2Y3"},"source":["這裡把$-\\theta$命名爲偏置$-b$，但是請注意，偏置和權重$w_{1}$、$w_{2}$的作用是不一樣的。具體地說，$w_{1}$、$w_{2}$是控制輸入信號的重要性的參數，而偏置是調整神經元被激活的容易程度（輸出信號爲$1$的程度）的參數。比如，若$b$爲$-0.1$則衹要輸入信號的加權總和超過$0.1$，神經元就會被激活。像這樣，偏置的值決定了神經元被激活的容易程度。另外，這裡我們將$w_{1}$和$w_{2}$稱爲權重，將$b$稱爲偏置，但是根據上下文，有時也會將$b$、$w_{1}$、$w_{2}$這些參數統稱爲權重。"]},{"cell_type":"markdown","metadata":{"id":"KOOYS8x0HM97"},"source":["接着，我們繼續實現與非門和或門。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpN52mq2Hz6s","executionInfo":{"status":"ok","timestamp":1634397305722,"user_tz":-480,"elapsed":9,"user":{"displayName":"吳琛","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGGN8VBMjqC5bhUWpteK796KQCvMPqhZq6A2ZX0A=s64","userId":"14227993174234273213"}},"outputId":"a5e5244f-1026-483c-fe82-0aefd91bf3da"},"source":["def NAND(x1, x2):\n","  x = np.array([x1, x2])\n","  w = np.array([-0.5, -0.5])  # 僅權重和偏置與AND不同！\n","  b = 0.7\n","  temp = np.sum(w * x) + b\n","  if temp <= 0:\n","    return 0\n","  else:\n","    return 1\n","\n","def OR(x1, x2):\n","  x = np.array([x1, x2])\n","  w = np.array([0.5, 0.5])  # 僅權重和偏置與AND不同！\n","  b = -0.2\n","  temp = np.sum(w * x) + b\n","  if temp <= 0:\n","    return 0\n","  else:\n","    return 1\n","\n","print(\"測試與非門：\")\n","print(NAND(0, 0))\n","print(NAND(1, 0))\n","print(NAND(0, 1))\n","print(NAND(1, 1))\n","print()\n","print(\"測試或門：\")\n","print(OR(0, 0))\n","print(OR(1, 0))\n","print(OR(0, 1))\n","print(OR(1, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["測試與非門：\n","1\n","1\n","1\n","0\n","\n","測試或門：\n","0\n","1\n","1\n","1\n"]}]},{"cell_type":"markdown","metadata":{"id":"H7qo1WqbJRvp"},"source":["我們在前面介紹過，與門、與非門、或門是具有相同構造的感知機，區別衹在於權重參數的值。因此，在與非門和或門的實現中，僅設置權重和偏置的值這一點和與門的實現不同。"]},{"cell_type":"markdown","metadata":{"id":"4PhV4x2AUXnz"},"source":["## 2.4 感知機的局限性\n","現在我們已經知道，使用感知機可以實現與門、與非門、或門三種邏輯電路。現在我們來考慮一下異或門（XOR gate）。"]},{"cell_type":"markdown","metadata":{"id":"HaEH1ZtuUrsx"},"source":["### 2.4.1 異或門\n","異或門也被稱爲**邏輯異或**電路。如圖所示，僅當$x_{1}$或$x_{2}$中的一方爲$1$時，才會輸出$1$（「異或」是拒絕其他相同數字的意思）。那麽，要用感知機實現這個異或門的話，應該設定什麽樣的權重參數呢？\n","\n","<div align=\"center\">\n","<img alt=\"異或門的眞值表\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-5.png\" width=\"50%\">\n","<div style=\"display: inline-block;\"><strong>圖2-5 異或門的眞值表</strong></div>\n","</div>\n","\n","實際上，用前面介紹的感知機是無法實現這個異或門的。爲什麽用感知機可以實現與門、或門、卻無法實現異或門呢？下面我們嘗試通過畫圖來思考其中的原因。\n","\n","首先，我們試着將或門的動作形象化。或門的情況下，當權重參數$(b,w_{1},w_{2})=(-0.5,1.0,1.0)$時，可滿足或門的眞值表條件。此時，感知機可用下面的式(2.3)表示。\n","\n","$$\n","y = \n","\\begin{cases}\n","0 & (-0.5 + x_{1} + x_{2}) \\leq 0 \\\\\n","1 & (-0.5 + x_{1} + x_{2}) > 0\n","\\end{cases} \\tag{2.3}\n","$$\n","\n","式(2.3)表示的感知機會生成由直綫$-0.5+x_{1}+x_{2}=0$分割開的兩個空間。其中一個空間輸出$1$，另一個空間輸出$0$，如圖所示。\n","\n","<div align=\"center\">\n","<img alt=\"感知機的可視化\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-6.png\" width=\"50%\"/>\n","<div style=\"display: inline-block;color: #999;\"><strong>圖2-6 感知機的可視化：灰色區域是感知機輸出0的區域，這個區域與或門的性質一致</strong></div>\n","</div>\n","\n","或門在$(x_{1},x_{2})=(0,0)$時輸出$0$，在$(x_{1},x_{2})$爲$(0,1)$、$(1,0)$、$(1,1)$時輸出$1$。圖2-6中，&xcirc;表示$0$，&xutri;表示$1$。如果想製作或門，需要用直綫將圖2-6中的&xcirc;和&xutri;分開。實際上，剛才的那條直綫就將這4個點正確地分開了。\n","\n","那麽，換成異或門的話會如何呢？能否像或門那樣，用一條直綫作出分割圖2-7中的&xcirc;和&xutri;的空間呢？\n","\n","<div align=\"center\">\n","<img alt=\"嘗試異或門的分割\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-7.png\" width=\"50%\"/>\n","<div style=\"display: inline-block;color: #999;\"><strong>圖2-7 &xcirc;和&xutri;表示異或門的輸出。可否通過一條直綫作出分割&xcirc;和&xutri;的空間呢？</strong></div>\n","</div>\n","\n","想要用一條直綫將圖2-7中的&xcirc;和&xutri;分開，無論如何都做不到。事實上，用一條直綫是無法將&xcirc;和&xutri;分開的。\n"]},{"cell_type":"markdown","metadata":{"id":"rRFlbZzmoqyf"},"source":["### 2.4.2 綫性和非綫性\n","\n","圖2-7中的&xcirc;和&xutri;無法用一條直綫分開，但是如果將「直綫」這個限制條件去掉，就可以實現了。比如，我們可以像下圖那樣，作出分開&xcirc;和&xutri;的空間。\n","\n","<div align=\"center\">\n","<img alt=\"使用曲綫分開異或門\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-8.png\" width=\"50%\"/>\n","<div style=\"display: inline-block;color: #999;\"><strong>圖2-8 使用曲綫可以分開&xcirc;和&xutri;</strong></div>\n","</div>\n","\n","感知機的局限性就在於它衹能表示由一條直綫分割的空間。圖2-8這樣彎曲的曲綫無法用感知機表示。另外，由圖2-8這樣的曲綫分割而成的空問稱爲**分綫性**空間，由直綫分割而成的空間稱爲**綫性**空間。綫性、非綫性這兩個術語在機器學習領域很常見，可以將其想象成圖2-6和圖2-8所示的直綫和曲綫。\n","\n","<br/>\n","\n","*注意：*\n","\n","*本節講到的異或門的局限性，嚴格地講，應該是「單層感知機無法表示異或門」或者「單層感知機無法分離非綫性空間」。接下來，我們將看到通過組合感知機（疊加層）就可以實現異或門。*"]},{"cell_type":"markdown","metadata":{"id":"C3LLj-VAeJPb"},"source":["## 2.5 多層感知機\n","\n","感知機不能表示異或門讓人深感遺憾，但也無需悲觀。實際上，感知機的絕妙之處在於它可以「疊加層」（通過疊加層來表示異或門是本節的要點）。這裡，我們暫且不考慮疊加層具體是指什麽，先從其他視角來思考一下異或門的問題。"]},{"cell_type":"markdown","metadata":{"id":"ogJR2p1ZetBp"},"source":["### 2.5.1 已有門電路的組合\n","異或門的製作方法有很多，其中之一就是組合我們前面做好的與門、與非門、或門進行配置。這裡，與門、與非門、或門用圖2-9中的符號表示。另外，圖2-9中與非門前端的&xcirc;表示反轉輸出的意思。\n","\n","<div align=\"center\">\n","<img alt=\"與門、與非門、或門的符號\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-9.png\" width=\"70%\"/>\n","<div style=\"display: inline-block;color: #999;\"><strong>圖2-9 與門、與非門、或門的符號</strong></div>\n","</div>\n","\n","其實，衹要用與門、與非門、或門合理代替圖2-10中的各個「？」，就可以實現異或門。\n","\n","<div align=\"center\">\n","<img alt=\"代入？實現異或門\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-10.png\" width=\"70%\"/>\n","<div style=\"display: inline-block;color: #999;\"><strong>圖2-10 將與門、與非門、或門代入到「？」中，就可以實現異或門！</strong></div>\n","</div>\n","\n","異或門可以通過圖2-11所示的配置來實現。這裡$x_{1}$和$x_{2}$表示輸入信號，$y$表示輸出信號。$x_{1}$和$x_{2}$是與非門和或門的輸入，而與非門和或門的輸出則是與門的輸入。\n","\n","<div align=\"center\">\n","<img alt=\"通過組合與門、與非門、或門實現異或門\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-11.png\" width=\"70%\"/>\n","<div style=\"display: inline-block;color: #999;\"><strong>圖2-11 通過組合與門、與非門、或門實現異或門</strong></div>\n","</div>\n","\n","現在，我們來確認一下圖2-11的配置是否眞正實現了異或門。這裡，把$s_{1}$作爲與非門的輸出，把$s_{2}$作爲或門的輸出，填入眞值表中。結果如圖2-12所示，觀察$x_{1}$、$x_{2}$、$y$，可以發現確實符合異或門的輸出。\n","\n","<div align=\"center\">\n","<img alt=\"異或門的眞值表\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-12.png\" width=\"50%\"/>\n","<div style=\"display: inline-block;color: #999;\"><strong>圖2-12 異或門的眞值表</strong></div>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"_BZ8kfUfqQdF"},"source":["### 2.5.2 異或門的實現\n","下面我們試着用Python來實現圖2-11所示的異或門。使用之前定義的AND函數、NAND函數、OR函數，可以像下面這樣（輕鬆地）實現。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9vZt8lNqmrE","executionInfo":{"status":"ok","timestamp":1634397305722,"user_tz":-480,"elapsed":7,"user":{"displayName":"吳琛","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGGN8VBMjqC5bhUWpteK796KQCvMPqhZq6A2ZX0A=s64","userId":"14227993174234273213"}},"outputId":"3265c6ac-8860-494e-cb6c-eb5d418ad179"},"source":["def XOR(x1, x2):\n","  s1 = NAND(x1, x2)\n","  s2 = OR(x1, x2)\n","  y = AND(s1, s2)\n","  return y\n","\n","print(XOR(0, 0))\n","print(XOR(1, 0))\n","print(XOR(0, 1))\n","print(XOR(1, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","1\n","0\n"]}]},{"cell_type":"markdown","metadata":{"id":"CaNTiF5Wq-IW"},"source":["這樣，異或門的實現就完成了。下面我們試着用感知機的表示方法（明確地顯示神經元）來表示這個異或門，結果如圖2-13所示。\n","\n","<div align=\"center\">\n","<img alt=\"用感知機表示異或門\" src=\"https://raw.githubusercontent.com/wcshds/Deep-Learning/master/Sharing%20Images/2-13.png\" width=\"70%\"/>\n","<div style=\"display: inline-block;color: #999;\"><strong>圖2-13 用感知機表示異或門</strong></div>\n","</div>\n","\n","<br/>\n","\n","*注意：*\n","\n","*圖2-13中的感知機總共由3層構成，但是因爲擁有權重的層實質上衹有2層（第0層和第1層之間，第1層和第2層之間），所以稱爲「2層感知機」。不過，有的文獻認爲圖2-13的感知機是由3層構成的，因而將其稱爲「3層感知機」。*\n","\n","<br/>\n","\n","在圖2-13所示的2層感知機中，先在第0層和第1層的神經元之間進行信號的傳送和接收，然後在第1層和第2層之間進行信號的傳送和接收，具體如下所示。\n","\n","  1. 第0層的兩個神經元接收輸入信號，並將信號發送至第1層的神經元。\n","  2. 第1層的神經元將信號發送至第2層的神經元，第2層的神經元輸出$y$。\n","\n","這種2層感知機的運行過程可以比作流水綫的組裝作業。第1段（第1層）的工人對傳送過來的零件進行加工，完成後再傳送給第2段（第2層）的工人。第2層的工人對第1層的工人傳過來的零件進行加工，完成這個零件後出貨（輸出）。\n","\n","像這樣，在異或門的感知機中，工人之間不斷進行零件的傳送。通過這樣的結構（2層結構），感知機得以實現異或門。這可以解釋爲「單層感知機無法表達的東西，通過增加一層就可以解決」。也就是說，通過疊加層（加深層），感知機能進行更加靈活的表示。"]},{"cell_type":"markdown","metadata":{"id":"-zOlN8uNw4oG"},"source":["## 2.6 從與非門到計算機\n","\n","多層感知機可以實現比之前見到的電路更複雜的電路。比如，進行加法運算的加法器也可以用感知機實現。此外，將二進制轉換爲十進制的編碼器、滿足某些條件就輸出$1$的電路（用於等價檢驗的電路）等也可以用感知機表示。實際上，使用感知機甚至可以表示計算機！\n","\n","計算機是處理信息的機器。向計算機中輸入一些信息後，它會按照某種既定的方法進行處理，然後輸出結果。所謂「按照某種既定的方法進行處理」是指，計算機和感知機一樣，也有輸入和輸出，會按照某個既定的規則進行計算。\n","\n","人們一般會認爲計算機內部進行的處理非常複雜，而令人驚訝的是，實際上衹需要通過與非門的組合，就能再現計算機進行的處理。這一令人吃驚的事實說明了什麽呢？說明使用感知機也可以表示計算機。前面也介紹了，與非門可以使用感知機實現。也就是說，如果通過組合與非門可以實現計算機的話，那麽通過組合感知機也可以表示計算機（感知機的組合可以通過疊加了多層的單層感知機來表示）。\n","\n","綜上，多層感知機能夠進行複雜的表示，甚至可以構建計算機。那麽，什麽構造的感知機才能表示計算機呢？層級多深才可以構建計算機呢？\n","\n","理論上可以說2層感知機就能構建計算機。這是因爲，已有研究證明，2層感知機（嚴格地說是激活函數使用了非綫性的sigmoid函數的感知機，具體參照下一章）可以表示任意函數。但是，使用2層感知機的構造，通過設定合適的權重來構建計算機是一件非常累人的事情。實際上，在用與非門等低層的元件構建計算機的情況下，分階段地製作所需的零件（模塊）會比較自然，即先實現與門和或門，然後實現半加器和全加器，接着實現算數邏輯單元（ALU），然後實現CPU。因此，通過感知機表示計算機時，使用疊加了多層的構造來實現是比較自然的流程。\n","\n","本教程中不會實際來實現計算機，但是希望大家能夠記住，感知機通過疊加層能夠進行非綫性的表示，理論上還可以表示計算機進行的處理。"]}]}